{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Отличить стихи от прозы",
      "provenance": [],
      "authorship_tag": "ABX9TyP7WOIgJEg4eSu7wAx1nne8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EvGdk/Machine-Learning-HSE/blob/master/%D0%9E%D1%82%D0%BB%D0%B8%D1%87%D0%B8%D1%82%D1%8C_%D1%81%D1%82%D0%B8%D1%85%D0%B8_%D0%BE%D1%82_%D0%BF%D1%80%D0%BE%D0%B7%D1%8B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHHfz4Lu8eVE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip -qq install rusenttokenize --progress-bar off"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-XBbSCS8id0",
        "colab_type": "code",
        "outputId": "bf0062c7-8ad6-4c28-de44-3ad44a47e035",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "! pip install pymorphy2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.0MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Installing collected packages: pymorphy2-dicts, dawg-python, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyaBFMinjlfn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf1JPmILjT06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZDYK7VFjqCz",
        "colab_type": "code",
        "outputId": "a451376e-ed16-4eb0-dcd0-d98e749fc19c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seQft1Q08KoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from rusenttokenize import ru_sent_tokenize\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "pymorphy2_analyzer = MorphAnalyzer()\n",
        "import pymorphy2\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YTLPUyq8xlP",
        "colab_type": "code",
        "outputId": "50ae0ec1-99b3-4206-a77d-0f3971a12a8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"punkt\", quiet=True)\n",
        "nltk.download(\"stopwords\", quiet=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vR4qK00YlHcs",
        "colab_type": "code",
        "outputId": "8696db02-602f-4b94-b622-b4f23769d7cb",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 113
        }
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QyUQgc45e5U",
        "colab_type": "code",
        "outputId": "816169d4-3e69-4f26-f665-b4c969616859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "korpus.csv  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4jSg3sClNrP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('korpus.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s9vBReklQ9d",
        "colab_type": "code",
        "outputId": "ef10aac8-6a7b-4ba1-f644-bf6b3e45ecb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "      <th>type</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6440</th>\n",
              "      <td>170</td>\n",
              "      <td>Это оттого, что с людьми, с которыми она тепер...</td>\n",
              "      <td>prose</td>\n",
              "      <td>pasternak</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6441</th>\n",
              "      <td>171</td>\n",
              "      <td>Доступное, при желаньи, восхищенным пониманиям...</td>\n",
              "      <td>prose</td>\n",
              "      <td>pasternak</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6442</th>\n",
              "      <td>172</td>\n",
              "      <td>Они встречались, крепко спаянные его давностью...</td>\n",
              "      <td>prose</td>\n",
              "      <td>pasternak</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6443</th>\n",
              "      <td>173</td>\n",
              "      <td>Те, которым не пришлось возобновить временно п...</td>\n",
              "      <td>prose</td>\n",
              "      <td>pasternak</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6444</th>\n",
              "      <td>174</td>\n",
              "      <td>Все обзавелись семьями, у всех</td>\n",
              "      <td>prose</td>\n",
              "      <td>pasternak</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ...     author\n",
              "6440         170  ...  pasternak\n",
              "6441         171  ...  pasternak\n",
              "6442         172  ...  pasternak\n",
              "6443         173  ...  pasternak\n",
              "6444         174  ...  pasternak\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsErtseEsNOW",
        "colab_type": "text"
      },
      "source": [
        "# Вариант 1. CountVectorizer и MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAIvaYQkrtc7",
        "colab_type": "code",
        "outputId": "0f009b14-9b84-4839-db22-26daa32b5b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "vec = CountVectorizer()\n",
        "bag_of_words = vec.fit_transform(df.text)\n",
        "X_train, X_test, y_train, y_test = train_test_split(bag_of_words, df.type)\n",
        "nb = MultinomialNB()\n",
        "clf = nb.fit(X_train, y_train)\n",
        "print(classification_report(y_test, clf.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       poeme       0.87      0.67      0.76       554\n",
            "       prose       0.84      0.95      0.89      1058\n",
            "\n",
            "    accuracy                           0.85      1612\n",
            "   macro avg       0.86      0.81      0.82      1612\n",
            "weighted avg       0.85      0.85      0.85      1612\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXbGAwjqskuI",
        "colab_type": "text"
      },
      "source": [
        "# Вариант 2: CountVectorizer со стоп-словами, MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prn4ETIw2pNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "punctuation = list(punctuation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06tjUBIt1Lyk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "punct2 =['—', '«', '»', '–']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90xQUcuY5OPV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "punctuation2  =  list(punct2+punctuation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDTPpUJRsnI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise = stopwords.words('russian')\n",
        "noise_with_punct = stopwords.words('russian') + punctuation2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLmEJ26G7Cpl",
        "colab_type": "code",
        "outputId": "23139a51-46e0-4ae4-bd9f-391e8fb18911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(noise)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "151"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJfBR-TcsuE_",
        "colab_type": "code",
        "outputId": "fb8cfdfa-c6fe-4e77-c7c7-fbfca6549cdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "vec = CountVectorizer(tokenizer=word_tokenize, stop_words= noise)\n",
        "bag_of_words = vec.fit_transform(df.text)\n",
        "X_train, X_test, y_train, y_test = train_test_split(bag_of_words, df.type)\n",
        "nb = MultinomialNB()\n",
        "clf = nb.fit(X_train, y_train)\n",
        "print(classification_report(y_test, clf.predict(X_test))) #без включения пунктуации в стоп слова"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       poeme       0.88      0.69      0.78       563\n",
            "       prose       0.85      0.95      0.90      1049\n",
            "\n",
            "    accuracy                           0.86      1612\n",
            "   macro avg       0.87      0.82      0.84      1612\n",
            "weighted avg       0.86      0.86      0.86      1612\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EE68oHMth4Z",
        "colab_type": "code",
        "outputId": "a80d1a7f-bd9a-46d8-e969-f37df4738048",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "vec = CountVectorizer(tokenizer=word_tokenize, stop_words=noise_with_punct)\n",
        "bag_of_words = vec.fit_transform(df.text)\n",
        "X_train, X_test, y_train, y_test = train_test_split(bag_of_words, df.type)\n",
        "nb = MultinomialNB()\n",
        "clf = nb.fit(X_train, y_train)\n",
        "print(classification_report(y_test, clf.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       poeme       0.82      0.77      0.79       556\n",
            "       prose       0.88      0.91      0.90      1056\n",
            "\n",
            "    accuracy                           0.86      1612\n",
            "   macro avg       0.85      0.84      0.85      1612\n",
            "weighted avg       0.86      0.86      0.86      1612\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fkwyb6S6xnJ",
        "colab_type": "text"
      },
      "source": [
        "### Веса признаков:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jwnn4uM8z7ct",
        "colab_type": "code",
        "outputId": "8a49a29e-cb8c-42f6-9392-08ebec089a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "clf.coef_.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 27611)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBfkZk1qz7Yw",
        "colab_type": "code",
        "outputId": "05562f11-3f0f-4320-854d-43bc8e601855",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "max(clf.coef_[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-5.050309155015829"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnABvoe8z7V3",
        "colab_type": "code",
        "outputId": "d43979d0-8e9e-4460-8482-0c275e2f34f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(max(enumerate(clf.coef_[0]), key=lambda pair: pair[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6044, -5.050309155015829)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RziBOiFl0qC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_to_word = {\n",
        "    ind: word\n",
        "    for (word, ind)\n",
        "    in vec.vocabulary_.items()\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahNtryDQ0wO1",
        "colab_type": "code",
        "outputId": "63f0e573-3a6a-4507-9251-55e7fb3bade8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "index_to_word[6044]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'её'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHNSWH5O04Eb",
        "colab_type": "code",
        "outputId": "e8591ce1-0a7d-4ab1-a853-04209fab1bb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "top_features = sorted(enumerate(clf.coef_[0]), key=lambda pair: pair[1], reverse=True)[:20]\n",
        "for index, value in top_features:\n",
        "  print(index_to_word[index])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "её\n",
            "это\n",
            "ещё\n",
            "всё\n",
            "очень\n",
            "сказал\n",
            "глаза\n",
            "сказала\n",
            "неё\n",
            "что-то\n",
            "стал\n",
            "возле\n",
            "своей\n",
            "руку\n",
            "натали\n",
            "руки\n",
            "день\n",
            "ко\n",
            "стала\n",
            "которой\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_ZFatjv-Ug7",
        "colab_type": "text"
      },
      "source": [
        "## Проверим классификатор"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6txyje9-cYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vector1 = vec.transform([\"\"\" Духовной жаждою томим,\n",
        "В пустыне мрачной я влачился, —\n",
        "И шестикрылый серафим\n",
        "На перепутье мне явился.\n",
        "Перстами легкими как сон\n",
        "Моих зениц коснулся он.\n",
        "Отверзлись вещие зеницы,\n",
        "Как у испуганной орлицы.\n",
        "Моих ушей коснулся он, —\n",
        "И их наполнил шум и звон:\n",
        "И внял я неба содроганье,\n",
        "И горний ангелов полет,\n",
        "И гад морских подводный ход,\n",
        "И дольней лозы прозябанье.\"\"\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQfSNq6u-jIo",
        "colab_type": "code",
        "outputId": "eedb8c40-ec7e-4096-a020-623524f29539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "clf.predict(vector1) #Пушкин \"Пророк\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['poeme'], dtype='<U5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eLhmBA7-5kJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vector2 = vec.transform([\"\"\" Однажды играли в карты у конногвардейца Нарумова. Долгая зимняя ночь прошла незаметно; сели ужинать в пятом часу утра. Те, которые остались в выигрыше, ели с большим апетитом; прочие, в рассеянности, сидели перед пустыми своими приборами. Но шампанское явилось, разговор оживился, и все приняли в нем участие.\n",
        "\n",
        "-- Что ты сделал, Сурин? -- спросил хозяин.\n",
        "\n",
        "-- Проиграл, по обыкновению. Надобно признаться, что я несчастлив: играю мирандолем, никогда не горячусь, ничем меня с толку не собьешь, а всё проигрываюсь!\"\"\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPZdDly5_MZx",
        "colab_type": "code",
        "outputId": "5a8a5198-098c-4e9d-e3b7-d3b78c5c81f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "clf.predict(vector2) #Это Пушкин, \"Пиковая дама\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['prose'], dtype='<U5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-ubfN89_SX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vector3 = vec.transform([\"\"\" …Я бы хотела жить с Вами\n",
        "В маленьком городе,\n",
        "Где вечные сумерки\n",
        "И вечные колокола.\n",
        "И в маленькой деревенской гостинице —\n",
        "Тонкий звон\n",
        "Старинных часов — как капельки времени.\n",
        "И иногда, по вечерам, из какой-нибудь мансарды —\n",
        "Флейта,\n",
        "И сам флейтист в окне.\n",
        "И большие тюльпаны на окнах.\n",
        "И может быть, Вы бы даже меня не любили…\n",
        "\n",
        "Посреди комнаты — огромная изразцовая печка,\n",
        "На каждом изразце — картинка:\n",
        "Роза — сердце — корабль. —\n",
        "А в единственном окне —\n",
        "Снег, снег, снег.\n",
        "\n",
        "Вы бы лежали — каким я Вас люблю: ленивый,\n",
        "Равнодушный, беспечный.\n",
        "Изредка резкий треск\n",
        "Спички.\n",
        "\n",
        "Папироса горит и гаснет,\n",
        "И долго-долго дрожит на ее краю\n",
        "Серым коротким столбиком — пепел.\n",
        "Вам даже лень его стряхивать —\n",
        "И вся папироса летит в огонь.\"\"\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWPYkwOUBHTw",
        "colab_type": "code",
        "outputId": "64553000-a098-49fd-92c8-e2ffd61eccf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "clf.predict(vector3) # А вот белый стих Марины Цветаевой"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['prose'], dtype='<U5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz9sSJzWBMP_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vector4 = vec.transform([\"\"\" Она пришла с мороза,\n",
        "Раскрасневшаяся,\n",
        "Наполнила комнату\n",
        "Ароматом воздуха и духов,\n",
        "Звонким голосом\n",
        "И совсем неуважительной к занятиям\n",
        "Болтовней.\n",
        "Она немедленно уронила на пол\n",
        "Толстый том художественного журнала,\n",
        "И сейчас же стало казаться,\n",
        "Что в моей большой комнате\n",
        "Очень мало места.\n",
        "Всё это было немножко досадно\n",
        "И довольно нелепо.\n",
        "Впрочем, она захотела,\n",
        "Чтобы я читал ей вслух «Макбета».\n",
        "Едва дойдя до пузырей земли,\n",
        "О которых я не могу говорить без волнения,\n",
        "Я заметил, что она тоже волнуется\n",
        "И внимательно смотрит в окно.\n",
        "Оказалось, что большой пестрый кот\n",
        "С трудом лепится по краю крыши,\n",
        "Подстерегая целующихся голубей.\n",
        "Я рассердился больше всего на то,\n",
        "Что целовались не мы, а голуби,\n",
        "И что прошли времена Паоло и Франчески.\"\"\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-WDpOPZQBL-7",
        "colab_type": "code",
        "outputId": "a888b06a-5b9c-4bc1-bd41-ba39652bc1a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "clf.predict(vector4) # Еще один белый стих. Александр Блок"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['prose'], dtype='<U5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwPAsHQBDStU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vector5 = vec.transform([\"\"\"Скоро Пасха. Наклонится Бог\n",
        "и дохнёт осторожно и жарко\n",
        "на убогие веточки в парке,\n",
        "на клубнику и чертополох.\n",
        "\n",
        "На крапиву и розовый куст,\n",
        "на живое и на неживое.\n",
        "И луга защекочет травою,\n",
        "и у ветра изменится вкус.\n",
        "\n",
        "По пустым одичалым лесам\n",
        "разлетится далёкое эхо\n",
        "то ли возгласа, а то ли смеха,\n",
        "тихий шёпот, шаги, голоса.\n",
        "\n",
        "И от горсточки сосен кривых,\n",
        "замордованных ближней деревней,\n",
        "вдруг пахнёт настоящим и древним,\n",
        "заставляющим прыгать и выть. \"\"\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFRPZbEdFOkQ",
        "colab_type": "code",
        "outputId": "48bd096b-17da-456a-ceed-76c3eb314e51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "clf.predict(vector5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['poeme'], dtype='<U5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk5Al8BQQN2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vector6 = vec.transform([\"\"\" Мертвенный пепел лун в трауре неба,\n",
        "Перхотью буквы звезд - мое имя,\n",
        "Чтобы его прочесть столько верст.\n",
        "\n",
        "Нибелунг, ничего у тебя не выйдет -\n",
        "кошка сдохла, хвост облез.\n",
        "И никто эту кровь нe выпьет, и никто\n",
        "ее плоть не съест.\n",
        "\n",
        "Ждешь? Врешь! В руках синдромная\n",
        "дрожь. Пьешь? Что ж...\n",
        "На то и солнечный день раскис\n",
        "в квадрате окна.\n",
        "И твоя мама больна, и твоя мама одна.\n",
        "Утешься собственным сном, где я -\n",
        "рябиной за окном.\n",
        "\n",
        "Вольному руки греть в пламени танго,\n",
        "Я заклинаю пить воды Конго,\n",
        "Чтобы пожар отмыть - петь да петь.\n",
        "\n",
        "Нибелунг, это палит костры туземка -\n",
        "бронзовая самка гну.\n",
        "И ты в клетке ее так крепко, что\n",
        "не поймешь, почему...\n",
        "\n",
        "\"Весна\" - похмельный сладко мурчит бес сна.\n",
        "Вчера была тарида, сегодня в горле блесна.\n",
        "Твое вино не беда, когда вина не ясна.\n",
        "Еще одним серым днем на кухне с грязным столом,\n",
        "Где я - рябиной за окном.\n",
        "\n",
        "В памяти млечных рун - смерти и корни.\n",
        "В рунах движения зла в миокарде,\n",
        "Чтобы его простить - два крыла.\n",
        "\n",
        "Нибелунг, это плавит твой воск конвектор -\n",
        "Перья крыльев вмерзли в сталь.\n",
        "Память в трубы уносит ветром... Улетай! Улетай!\n",
        "\n",
        "Семь бед - один ответ - Бога нет как нет,\n",
        "Где на столе будет гроб, там на столе будет спирт.\n",
        "Где за столом кто-то пьет, там под столом кто-то спит.\n",
        "Где человеческий лом присыпан хлоркой и льдом -\n",
        "Там я - рябиной за окном.\"\"\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur4R3CZLQTvi",
        "colab_type": "code",
        "outputId": "85566a01-594f-4a35-9dd6-a69eca7fac85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "clf.predict(vector6)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['poeme'], dtype='<U5')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MnW2eggwSyA",
        "colab_type": "text"
      },
      "source": [
        "# Вариант 3: CountVectorizer, NB, pymorphy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoF-gIxpv9Re",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "morph_analyzer = pymorphy2.MorphAnalyzer()\n",
        "russian_stopwords = stopwords.words('russian')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMrj0Evcvqff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_tokenize(text):\n",
        "    \n",
        "    text_preprocessed_tokenized = []\n",
        "        \n",
        "    for sentence in ru_sent_tokenize(text):\n",
        "        clean_words = [word.strip(string.punctuation) for word in word_tokenize(text)]\n",
        "        clean_words = [word for word in clean_words if word]\n",
        "        clean_words = [word.lower() for word in clean_words if word]\n",
        "        clean_words = [word for word in clean_words if word not in russian_stopwords]\n",
        "        clean_lemmas = [morph_analyzer.parse(word)[0].normal_form for word in clean_words]\n",
        "        text_preprocessed_tokenized.extend(clean_lemmas)\n",
        "\n",
        "    return text_preprocessed_tokenized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK7V6ffAvt1Z",
        "colab_type": "code",
        "outputId": "bf54408f-4ba9-4e12-86ba-682463fa50be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "vec = CountVectorizer(tokenizer=preprocess_tokenize)\n",
        "bag_of_words = vec.fit_transform(df.text)\n",
        "X_train, X_test, y_train, y_test = train_test_split(bag_of_words, df.type)\n",
        "nb = MultinomialNB()\n",
        "clf = nb.fit(X_train, y_train)\n",
        "print(classification_report(y_test, nb.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       poeme       0.87      0.72      0.79       540\n",
            "       prose       0.87      0.95      0.91      1072\n",
            "\n",
            "    accuracy                           0.87      1612\n",
            "   macro avg       0.87      0.83      0.85      1612\n",
            "weighted avg       0.87      0.87      0.87      1612\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X3yF9s5_3lW",
        "colab_type": "text"
      },
      "source": [
        "### Веса признаков:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMAwywZK_8C4",
        "colab_type": "code",
        "outputId": "11d05abf-21bc-485d-dac2-e52f346a738e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "clf.coef_.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 14430)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zdEOuntB6aD",
        "colab_type": "code",
        "outputId": "438bf295-a980-4b1f-d374-5d70553f270e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max(clf.coef_[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-3.3300817844282466"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LABaTjjq_2jY",
        "colab_type": "code",
        "outputId": "c2ca680e-1311-4b93-eb65-a1c1e47875e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(max(enumerate(clf.coef_[0]), key=lambda pair: pair[1]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14423, -3.3300817844282466)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZDho2L5A6M6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "index_to_word = {\n",
        "    ind: word\n",
        "    for (word, ind)\n",
        "    in vec.vocabulary_.items()\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fRAVv0JBANr",
        "colab_type": "code",
        "outputId": "9eaefe13-441f-4331-a7c2-5fa82befd1d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "index_to_word[14423]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'—'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rLa9QP7CSPh",
        "colab_type": "code",
        "outputId": "8607a28a-8129-4a03-9be9-2338b81c6623",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "top_features = sorted(enumerate(clf.coef_[0]), key=lambda pair: pair[1], reverse=True)[:10]\n",
        "for index, value in top_features:\n",
        "  print(index_to_word[index])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "—\n",
            "её\n",
            "весь\n",
            "это\n",
            "«\n",
            "»\n",
            "сказать\n",
            "рука\n",
            "глаз\n",
            "свой\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-E5SAqWwvbT",
        "colab_type": "text"
      },
      "source": [
        "# Вариант 4: LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gRZA_D8wunb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hydThpCGw8pv",
        "colab_type": "code",
        "outputId": "b52780fc-68b7-43b8-f182-5123e8b4e12a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "vec = CountVectorizer(tokenizer=preprocess_tokenize)\n",
        "bag_of_words = vec.fit_transform(df.text)\n",
        "X_train, X_test, y_train, y_test = train_test_split(bag_of_words, df.type)\n",
        "lr = LogisticRegression()\n",
        "clf = lr.fit(X_train, y_train)\n",
        "print(classification_report(y_test, clf.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       poeme       0.78      0.79      0.78       589\n",
            "       prose       0.88      0.87      0.87      1023\n",
            "\n",
            "    accuracy                           0.84      1612\n",
            "   macro avg       0.83      0.83      0.83      1612\n",
            "weighted avg       0.84      0.84      0.84      1612\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BquexO3pxRYn",
        "colab_type": "text"
      },
      "source": [
        "очень плохо(((( Попробуем без pymorphy:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrTOM8vfxbVO",
        "colab_type": "code",
        "outputId": "5355aab7-6109-4c10-be2d-2a75725e460c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "vec = CountVectorizer(tokenizer=word_tokenize)\n",
        "bag_of_words = vec.fit_transform(df.text)\n",
        "X_train, X_test, y_train, y_test = train_test_split(bag_of_words, df.type)\n",
        "lr = LogisticRegression()\n",
        "clf = lr.fit(X_train, y_train)\n",
        "print(classification_report(y_test, clf.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       poeme       0.79      0.82      0.80       541\n",
            "       prose       0.91      0.89      0.90      1071\n",
            "\n",
            "    accuracy                           0.86      1612\n",
            "   macro avg       0.85      0.85      0.85      1612\n",
            "weighted avg       0.87      0.86      0.87      1612\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIUtwftbxuEM",
        "colab_type": "text"
      },
      "source": [
        "Теперь то же самое со стоп-словами (с пунктуацией)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNxrCmnWx1l7",
        "colab_type": "code",
        "outputId": "54e7f4c0-db0e-42ef-ffd5-f8262687cf47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "vec = CountVectorizer(tokenizer=word_tokenize,stop_words=noise_with_punct )\n",
        "bag_of_words = vec.fit_transform(df.text)\n",
        "X_train, X_test, y_train, y_test = train_test_split(bag_of_words, df.type)\n",
        "lr = LogisticRegression()\n",
        "clf = lr.fit(X_train, y_train)\n",
        "print(classification_report(y_test, clf.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['``'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       poeme       0.88      0.54      0.67       552\n",
            "       prose       0.80      0.96      0.87      1060\n",
            "\n",
            "    accuracy                           0.82      1612\n",
            "   macro avg       0.84      0.75      0.77      1612\n",
            "weighted avg       0.83      0.82      0.80      1612\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYD6RymUyNZx",
        "colab_type": "text"
      },
      "source": [
        "Стоп - слова без пунктуации:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YcL6jnIyKUN",
        "colab_type": "code",
        "outputId": "d5b99533-65cc-4ffd-fce3-1a98c3104606",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        }
      },
      "source": [
        "vec = CountVectorizer(tokenizer=word_tokenize,stop_words=noise )\n",
        "bag_of_words = vec.fit_transform(df.text)\n",
        "X_train, X_test, y_train, y_test = train_test_split(bag_of_words, df.type)\n",
        "lr = LogisticRegression()\n",
        "clf = lr.fit(X_train, y_train)\n",
        "print(classification_report(y_test, clf.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       poeme       0.83      0.76      0.79       591\n",
            "       prose       0.87      0.91      0.89      1021\n",
            "\n",
            "    accuracy                           0.85      1612\n",
            "   macro avg       0.85      0.83      0.84      1612\n",
            "weighted avg       0.85      0.85      0.85      1612\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rz8eSeyEy_jc",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzI5eAgwyg1e",
        "colab_type": "text"
      },
      "source": [
        "# Вариант 5: CountVectorizer, LogisticRegression, Bi-gramms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f91gp44yfkl",
        "colab_type": "code",
        "outputId": "f7b64b26-159c-4f7f-e97c-104b0fbd69dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "vec = CountVectorizer(ngram_range=(1, 3)) \n",
        "bag_of_words = vec.fit_transform(df.text)\n",
        "X_train, X_test, y_train, y_test = train_test_split(bag_of_words, df.type)\n",
        "lr = LogisticRegression()\n",
        "clf = lr.fit(X_train, y_train)\n",
        "print(classification_report(y_test, clf.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       poeme       0.81      0.58      0.67       571\n",
            "       prose       0.80      0.93      0.86      1041\n",
            "\n",
            "    accuracy                           0.80      1612\n",
            "   macro avg       0.81      0.75      0.77      1612\n",
            "weighted avg       0.80      0.80      0.79      1612\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKIN2l0s6PZu",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_Cn2jEh-z7K",
        "colab_type": "text"
      },
      "source": [
        "## GridSearch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yAKX4Bc6QHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lqe9XPmr_hkz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_grid = {'classifier' : [LogisticRegression()],\n",
        "     'classifier__penalty' : ['l1', 'l2'],\n",
        "    'classifier__C' : np.logspace(-4, 4, 20),\n",
        "    'classifier__solver' : ['liblinear']\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Llr-A8dEmrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_clf_acc = GridSearchCV(clf, param_grid = grid_values)\n",
        "grid_clf_acc.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM47DKf5FZvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"tuned hpyerparameters :(best parameters) \",grid_clf_acc.best_params_)\n",
        "print(\"accuracy :\", grid_clf_acc.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drBGBzuhGiXX",
        "colab_type": "code",
        "outputId": "89f790f8-21d2-46e5-c804-d2042a117438",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "vectorizer = CountVectorizer(tokenizer=preprocess_tokenize, stop_words=noise_with_punct)\n",
        "bow = vectorizer.fit_transform(df.text)\n",
        "X_train, X_test, y_train, y_test = train_test_split(bow, df.type)\n",
        "lr = LogisticRegression(C=25, penalty='l2', solver = 'saga')\n",
        "clf = lr.fit(X_train, y_train)\n",
        "print(classification_report(y_test, clf.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       poeme       0.82      0.67      0.74       571\n",
            "       prose       0.84      0.92      0.88      1041\n",
            "\n",
            "    accuracy                           0.83      1612\n",
            "   macro avg       0.83      0.80      0.81      1612\n",
            "weighted avg       0.83      0.83      0.83      1612\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZeVPnU0LnZu",
        "colab_type": "text"
      },
      "source": [
        "## Прочие классификаторы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa1RH3zpLbVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5GRvqzbNC_S",
        "colab_type": "text"
      },
      "source": [
        "### RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_yoTHOTL3mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vec = CountVectorizer(tokenizer=preprocess_tokenize)\n",
        "bag_of_words = vec.fit_transform(df.text)\n",
        "X_train, X_test, y_train, y_test = train_test_split(bag_of_words, df.type)\n",
        "rf = RandomForestClassifier()\n",
        "clf = rf.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGbAb9UiM1lY",
        "colab_type": "code",
        "outputId": "26e396b7-2ded-426b-cce6-8519cf33548b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "print(classification_report(y_test, rf.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       poeme       0.76      0.63      0.69       541\n",
            "       prose       0.83      0.90      0.86      1071\n",
            "\n",
            "    accuracy                           0.81      1612\n",
            "   macro avg       0.80      0.77      0.78      1612\n",
            "weighted avg       0.81      0.81      0.81      1612\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ao1t0hcNLZ0",
        "colab_type": "text"
      },
      "source": [
        "### KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G3c-9t2NH8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vec = CountVectorizer(tokenizer=preprocess_tokenize)\n",
        "bag_of_words = vec.fit_transform(df.text)\n",
        "X_train, X_test, y_train, y_test = train_test_split(bag_of_words, df.type)\n",
        "kn = KNeighborsClassifier()\n",
        "clf = kn.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VU7Tv7-NlHJ",
        "colab_type": "code",
        "outputId": "73ad02f5-a96b-454e-aa7c-9590f2f8e5f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "print(classification_report(y_test, kn.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       poeme       0.58      0.41      0.48       541\n",
            "       prose       0.74      0.85      0.79      1071\n",
            "\n",
            "    accuracy                           0.70      1612\n",
            "   macro avg       0.66      0.63      0.64      1612\n",
            "weighted avg       0.69      0.70      0.69      1612\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIXHjChINq0W",
        "colab_type": "text"
      },
      "source": [
        "### SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqXYv03BNvNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vec = CountVectorizer(tokenizer=preprocess_tokenize)\n",
        "bag_of_words = vec.fit_transform(df.text)\n",
        "X_train, X_test, y_train, y_test = train_test_split(bag_of_words, df.type)\n",
        "svc = SVC()\n",
        "clf = svc.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqZdIuVvN-eN",
        "colab_type": "code",
        "outputId": "92c1f7ae-16b7-4c49-f3da-50adc40fc2a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "print(classification_report(y_test, svc.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       poeme       0.73      0.77      0.75       575\n",
            "       prose       0.87      0.84      0.86      1037\n",
            "\n",
            "    accuracy                           0.82      1612\n",
            "   macro avg       0.80      0.81      0.80      1612\n",
            "weighted avg       0.82      0.82      0.82      1612\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e6gwMaZOIdD",
        "colab_type": "text"
      },
      "source": [
        "### DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCdDxMW1OKp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vec = CountVectorizer(tokenizer=preprocess_tokenize)\n",
        "bag_of_words = vec.fit_transform(df.text)\n",
        "X_train, X_test, y_train, y_test = train_test_split(bag_of_words, df.type)\n",
        "dt = DecisionTreeClassifier()\n",
        "clf = dt.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhJWVoaUOa8P",
        "colab_type": "code",
        "outputId": "7fdd21dd-bd5e-49b1-f58c-3b6cce31c060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "print(classification_report(y_test, dt.predict(X_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       poeme       0.77      0.50      0.61       586\n",
            "       prose       0.76      0.92      0.83      1026\n",
            "\n",
            "    accuracy                           0.77      1612\n",
            "   macro avg       0.77      0.71      0.72      1612\n",
            "weighted avg       0.77      0.77      0.75      1612\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}